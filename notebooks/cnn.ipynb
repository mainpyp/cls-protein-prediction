{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is official pytorch tutorial: <a href=https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py> Blitz Tutorial<a>\n",
    "\n",
    "What is done in this tutorial:\n",
    "    1. Load and normalize the CIFAR10 training and test datasets using torchvision\n",
    "    2. Define a Convolutional Neural Network\n",
    "    3. Define a loss function\n",
    "    4. Train the network on the training data\n",
    "    5. Test the network on the test data\n",
    "\n",
    "TORCHVISION:\n",
    "    The torchvision package consists of popular datasets, model architectures,\n",
    "    and common image transformations for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "embeddings = h5py.File(\"../../data/embeddings.h5\", \"r\")\n",
    "with open(\"../../data/seq_anno_hash.pickle\", 'rb') as handle:\n",
    "    proteins_and_hashes = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638\n",
      "516\n"
     ]
    },
    {
     "data": {
      "text/plain": "     prot_id  label\n1240  P31716   G_SP\n2049  Q24537      G\n1660  Q9VWW0      G\n3495  Q0GGX2      G\n1260  P13423   G_SP\n...      ...    ...\n1801  P18146      G\n4276  Q21874  SP_TM\n2501  Q13415      G\n2687  Q9HGP0      G\n582   Q13093   G_SP\n\n[4638 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prot_id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1240</th>\n      <td>P31716</td>\n      <td>G_SP</td>\n    </tr>\n    <tr>\n      <th>2049</th>\n      <td>Q24537</td>\n      <td>G</td>\n    </tr>\n    <tr>\n      <th>1660</th>\n      <td>Q9VWW0</td>\n      <td>G</td>\n    </tr>\n    <tr>\n      <th>3495</th>\n      <td>Q0GGX2</td>\n      <td>G</td>\n    </tr>\n    <tr>\n      <th>1260</th>\n      <td>P13423</td>\n      <td>G_SP</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1801</th>\n      <td>P18146</td>\n      <td>G</td>\n    </tr>\n    <tr>\n      <th>4276</th>\n      <td>Q21874</td>\n      <td>SP_TM</td>\n    </tr>\n    <tr>\n      <th>2501</th>\n      <td>Q13415</td>\n      <td>G</td>\n    </tr>\n    <tr>\n      <th>2687</th>\n      <td>Q9HGP0</td>\n      <td>G</td>\n    </tr>\n    <tr>\n      <th>582</th>\n      <td>Q13093</td>\n      <td>G_SP</td>\n    </tr>\n  </tbody>\n</table>\n<p>4638 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_prot = [list(map(lambda x:[x,key], list(proteins_and_hashes[key].keys()))) for key in proteins_and_hashes]\n",
    "label_prot = list(chain.from_iterable(label_prot))\n",
    "label_prot = pd.DataFrame(label_prot, columns=[\"prot_id\", \"label\"])\n",
    "\n",
    "X_train, X_test = train_test_split(label_prot, test_size = 0.1, train_size=0.9, random_state=42, stratify=label_prot[\"label\"])\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_embeddings = list()\n",
    "train_labels = list()\n",
    "train_protein_ids = list()\n",
    "for index, row in X_train.iterrows():\n",
    "    hash_code = proteins_and_hashes[row[\"label\"]][row[\"prot_id\"]][2]\n",
    "    mean_embedding = np.mean(embeddings.get(hash_code), axis=0)\n",
    "    label = row[\"label\"]\n",
    "    id = row[\"prot_id\"]\n",
    "    train_protein_ids.append(id)\n",
    "    train_embeddings.append(mean_embedding)\n",
    "    train_labels.append(label)\n",
    "\n",
    "test_embeddings = list()\n",
    "test_labels = list()\n",
    "test_protein_ids = list()\n",
    "for index, row in X_test.iterrows():\n",
    "    hash_code = proteins_and_hashes[row[\"label\"]][row[\"prot_id\"]][2]\n",
    "    mean_embedding = np.mean(embeddings.get(hash_code), axis=0)\n",
    "    label = row[\"label\"]\n",
    "    id = row[\"prot_id\"]\n",
    "    test_protein_ids.append(id)\n",
    "    test_embeddings.append(mean_embedding)\n",
    "    test_labels.append(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "label_mappings = {\n",
    "    'G_SP': 0,\n",
    "     'G': 1,\n",
    "     'SP_TM': 2,\n",
    "     'TM': 3\n",
    "}\n",
    "reverse_label_mappings = {val: key for key, val in label_mappings.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_embeddings = torch.Tensor(np.array(train_embeddings))\n",
    "train_labels = torch.Tensor([label_mappings[label] for label in  train_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "test_embeddings = torch.Tensor(np.array(test_embeddings))\n",
    "test_labels = torch.Tensor([label_mappings[label] for label in  test_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_labels = one_hot(train_labels.to(torch.int64), 4)\n",
    "dataset = TensorDataset(train_embeddings, train_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "test_labels = one_hot(test_labels.to(torch.int64), 4)\n",
    "test_dataset = TensorDataset(test_embeddings, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\" Define a model with two convolution layers each followed by a Max Pooling layer\n",
    "    Then the embeddings are Flattened and forwarded into two FCls.\n",
    "    The last layer is a FCL with 10 neurons.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.conv1 = nn.Conv1d(512, 512, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.conv1 = nn.Conv1d(512, 512, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.conv3 = nn.Conv1d(256, 256, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        self.fc4 = nn.Linear(256, 4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        #x = F.softmax(x, dim=4)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = CNN()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# The function is indicating the performance of the model.\n",
    "# During the training process this function should be minimized\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# The minimization is achieved through Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [7, 10, 1], but got 2-dimensional input of size [2, 10] instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/hc/syymx7gj2rj7mmw3bymr8s0c0000gn/T/ipykernel_5611/1059597531.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mConv1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m7\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstride\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/PyTorchTest/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/PyTorchTest/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 301\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/PyTorchTest/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    295\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    296\u001B[0m                             _single(0), self.dilation, self.groups)\n\u001B[0;32m--> 297\u001B[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001B[0m\u001B[1;32m    298\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected 3-dimensional input for 3-dimensional weight [7, 10, 1], but got 2-dimensional input of size [2, 10] instead"
     ]
    }
   ],
   "source": [
    "input = torch.randn(2, 10)\n",
    "m = nn.Conv1d(10, 7, 1, stride=2)\n",
    "m(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 1.178\n",
      "[1, 200] loss: 1.043\n",
      "[1, 300] loss: 1.045\n",
      "[1, 400] loss: 0.858\n",
      "[1, 500] loss: 0.555\n",
      "[1, 600] loss: 0.414\n",
      "[1, 700] loss: 0.352\n",
      "[1, 800] loss: 0.453\n",
      "[1, 900] loss: 0.492\n",
      "[1, 1000] loss: 0.387\n",
      "[1, 1100] loss: 0.302\n",
      "[2, 100] loss: 0.316\n",
      "[2, 200] loss: 0.315\n",
      "[2, 300] loss: 0.221\n",
      "[2, 400] loss: 0.264\n",
      "[2, 500] loss: 0.189\n",
      "[2, 600] loss: 0.109\n",
      "[2, 700] loss: 0.118\n",
      "[2, 800] loss: 0.168\n",
      "[2, 900] loss: 0.209\n",
      "[2, 1000] loss: 0.198\n",
      "[2, 1100] loss: 0.104\n",
      "[3, 100] loss: 0.146\n",
      "[3, 200] loss: 0.093\n",
      "[3, 300] loss: 0.113\n",
      "[3, 400] loss: 0.143\n",
      "[3, 500] loss: 0.103\n",
      "[3, 600] loss: 0.079\n",
      "[3, 700] loss: 0.098\n",
      "[3, 800] loss: 0.104\n",
      "[3, 900] loss: 0.130\n",
      "[3, 1000] loss: 0.149\n",
      "[3, 1100] loss: 0.070\n",
      "[4, 100] loss: 0.126\n",
      "[4, 200] loss: 0.067\n",
      "[4, 300] loss: 0.077\n",
      "[4, 400] loss: 0.093\n",
      "[4, 500] loss: 0.096\n",
      "[4, 600] loss: 0.054\n",
      "[4, 700] loss: 0.106\n",
      "[4, 800] loss: 0.075\n",
      "[4, 900] loss: 0.093\n",
      "[4, 1000] loss: 0.120\n",
      "[4, 1100] loss: 0.045\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \"\"\"\n",
    "        shape of inputs: torch.Size([4, 3, 32, 32])\n",
    "            Batchsize: 4\n",
    "            Channels: 3 (Red, Green, Blue)\n",
    "            Image size: 32 x 32\n",
    "\n",
    "        labels: tensor([9, 3, 0, 3])\n",
    "            9: class of image 0 in batch\n",
    "            3: class of image 1 in batch\n",
    "            ...\n",
    "        \"\"\"\n",
    "        inputs, labels = data\n",
    "\n",
    "        \"\"\" zero the parameter gradients after every batch\n",
    "        This is necessary because the gradients (directions of how the weigths and biases\n",
    "        will be updated) are accumulated in each backward pass.\n",
    "        https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
    "        \"\"\"\n",
    "        optimizer.zero_grad()  # SGD\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        # shape outputs: torch.Size([4, 10])\n",
    "        # for every image a prediction\n",
    "        #print(f\"{inputs}\")\n",
    "        outputs = net(inputs)\n",
    "        #print(f\"{outputs} \\t {labels}\")\n",
    "\n",
    "        # the first iteration CrossEntropy: tensor(2.3100, grad_fn=<NllLossBackward0>)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # running loss after 3 iterations: 6.894119024276733\n",
    "        # Why is the loss added?\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {(running_loss / 99):.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the model on the test data\n",
    "This could be done with TorchMetrics but we will do this manually here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 516 test embeddings: 95.74\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, labels = torch.max(labels.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {len(test_labels)} test embeddings: {(100 * correct / total):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class G_SP  is: 96.2 %\n",
      "Accuracy for class G     is: 99.3 %\n",
      "Accuracy for class SP_TM is: 81.0 %\n",
      "Accuracy for class TM    is: 89.7 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nAccuracy for class G_SP  is: 0.0 %\\nAccuracy for class G     is: 100.0 %\\nAccuracy for class SP_TM is: 0.0 %\\nAccuracy for class TM    is: 0.0 %\\n'"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "classes = list(label_mappings.keys())\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                         accuracy))\n",
    "\n",
    "\"\"\"\n",
    "Accuracy for class G_SP  is: 0.0 %\n",
    "Accuracy for class G     is: 100.0 %\n",
    "Accuracy for class SP_TM is: 0.0 %\n",
    "Accuracy for class TM    is: 0.0 %\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create hashsum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}